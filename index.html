<!DOCTYPE html>

<!-- website built from: -->
<!-- https://leap-workshop.github.io/ -->
<!-- https://ai-workshops.github.io/generalizable-policy-learning-in-the-physical-world/ -->

<html lang="en">
<!-- css from https://github.com/ai-workshops/ai-workshops.github.io/blob/master/generalizable-policy-learning-in-the-physical-world/style.css -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css"
  integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

<link rel="icon"
  href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text x=%22-.1em%22 y=%22.9em%22 font-size=%2280%22>ü§ñ</text></svg>">

<!-- jQuery library -->
<script src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

<!-- Latest compiled JavaScript -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js"
  integrity="sha384-w1Q4orYjBQndcko6MimVbzY0tgp4pWB4lZ7lr30WKz0vr/aWKhXdBNmNb5D92v7s" crossorigin="anonymous"></script>



<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta charset="utf-8">
  <link rel="stylesheet" href="bootstrap/css/bootstrap.min.css">
  <title>Resource-Rational Robot Learning: Proposal for the Rational Robots Workshop</title>
  <link rel="stylesheet" href="css/style.css">

  <style>
    .collapsible {
      background-color: #fff;
      color: #000;
      cursor: pointer;
      padding: 18px;
      width: 100%;
      border: 0px solid white;
      text-align: center;
      outline: none;
      font-size: 15px;
    }

    .title-container {
      width: 100%;
      margin: auto;
      padding: 40px 20px;
      color: black;
      background: white;
      background-image: linear-gradient(135deg,#00c86e, #e1f7e6, #00c86e);
      /* background-image: url("imgs/corl2024_background.png"); */
      background-size: cover;
      background-position: center;
      background-repeat: no-repeat, repeat;
      display: flex;
      flex-direction: column;
      justify-content: center;
      margin-top: 55px;
    }

    .active,
    .collapsible:hover {
      background-color: #bbb;
    }

    .content {
      padding: 5px 18px;
      display: none;
      overflow: hidden;
      background-color: #f1f1f1;
    }

    .triangle-up {
      width: 0;
      height: 0;
      border-left: 10px solid transparent;
      border-right: 10px solid transparent;
      border-bottom: 20px solid rgb(255, 255, 255);
      float: right;
    }

    .triangle-down {
      width: 0;
      height: 0;
      border-left: 10px solid transparent;
      border-right: 10px solid transparent;
      border-top: 20px solid rgb(255, 255, 255);
      float: right;
    }
  </style>
</head>

<body>
  <nav class="navbar navbar-expand-xl navbar-expand-lg navbar-expand-custom navbar-fixed-top sticky-nav">
    <button class="navbar-toggler navbar-light" type="button" data-toggle="collapse" data-target="#main-navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="main-navigation">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link" href="index.html#">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="index.html#discussion">Discussion</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="index.html#topics_of_interest">Topics</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="index.html#committee">Committee</a>
        </li>
      </ul>
    </div>
  </nav>

  <div class="title-container">
    <div style="text-align: center;">
      <h1 style="width:80%;margin:auto;">Resource-Rational Robot Learning:</h1>
      <div class="subtitle">Proposal for the Rational Robots Workshop</div>
      <!-- <h3>Email: <a href="mailto:tbd@tbd.com">tbd@tbd.com</a></h3> -->
    </div>
  </div>

  <div class="container" style="padding-bottom: 0px;">
    <div class="section" id="overview">
      <h2>Overview</h2>
      <p>
        <center>
        <i>"Intelligence: The ability to use optimally limited resources... to achieve a set of goals..."</i>
        <br>
        ~Ray Kurzweil, <i>The Age of Spiritual Machines,</i> 1999
        </center>
      </p>
      <p>
        This workshop explores autonomous robot learners that can rapidly learn in challenging unstructured environments by optimally using all available resources to achieve their mission. In such settings, learning must be fast to minimize downtime, cost-efficient to ensure viability, and human-aware so that robots can safely learn from and act alongside humans. Achieving this requires <b class="font-weight-bold"><i>resource rationality</i></b>: careful deliberation about what to learn, and how to allocate resources like time, computation, and human assistance based on their cost-benefit tradeoff. However, most state-of-the-art robot learning approaches either disregard resource rationality and thus require expensive data collection, or delegate such decisions to humans.
      </p>
      <p>
        Various communities in robotics and AI interested in efficient learning have independently explored aspects of resource rationality, for example, through efficient use of human feedback by the human-robot interaction community, learning from diverse sources of data by the imitation learning community, and integration with model-based reasoning by the learning-to-plan community. This workshop seeks to create a common forum among researchers and practitioners to exchange insights, discuss key questions, and share a collective path forward to robot intelligence through the unifying lens of resource rationality.
      </p>
      <p>
        Resource rationality has broad impact for not only many different problems within robot learning, but more widely, to adjacent fields related to embodied intelligence, such as planning, cognitive science (understanding how human learning can be achieved given biological computational limitations) and causality (understanding how to learn with respect to the processes that generate the data, rather than the data alone). Therefore, our intended audience includes the robot learning, planning, machine learning, cognitive science, and causality communities.
      </p>
    </div>

    <div class="section" id="discussion">
      <h2>Discussion and Structure</h2>
      <p>
        Our workshop aims to foster and highlight the many different perspectives that make up work in resource-rational robot learning. To that end, we organize our workshop around three sessions, corresponding to different resources that a robot must leverage: <b class="font-weight-bold"><font color="#CD5C5C">models</font></b>, <b class="font-weight-bold"><font color="#6495ED">training data</font></b>, and <b class="font-weight-bold"><font color="#BA55D3">human help</font></b>. Each session has a series of open-ended questions for speakers, the audience, and the final panel to engage with:
      </p>
      <ul>
        <li>
          <b class="font-weight-bold"><font color="#CD5C5C">Models: What desiderata should a world model for a rational robot satisfy?</font></b> The world model must not only be learned efficiently but must also be efficient to plan with. We will discuss how data to learn such models should be acquired and also the tradeoffs of different representations.
        </li>
        <li>
          <b class="font-weight-bold"><font color="#CD5C5C">Models: What methods can robots leverage to improve model-based decision-making?</font></b> Methods that are interpretable and offer explanations, such as those from causality, can empower robots to answer "How?" and "Why?" questions.
        </li>
        <li>
          <b class="font-weight-bold"><font color="#6495ED">Data: What is the optimal combination of simulated and physical data?</font></b> Simulated data is significantly cheaper to collect than physical experience. How can we best make use of simulated data to minimize the total cost of data collection?
        </li>
        <li>
          <b class="font-weight-bold"><font color="#6495ED">Data: Should data collection be curated solely by humans or should robots participate actively?</font></b> Most existing large-scale data collection efforts rely on humans to provide demonstrations. Such efforts can benefit from active robot data collection, in which robots autonomously identify and collect relevant experiences for learning.
        </li>
        <li>
          <b class="font-weight-bold"><font color="#BA55D3">Humans: How should robots best learn from human instruction?</font></b> In contrast with prevalent imitation learning approaches where robots learn passively from human demonstrations, interactive learning procedures that draw on a theory of minds may allow for more efficient learning from instruction and demonstration.
        </li>
        <li>
          <b class="font-weight-bold"><font color="#BA55D3">Humans: How to leverage diverse types of human feedback and interventions?</font></b> Use of different interaction types, such as corrections and preference queries, can help robots learn more nuanced and personalized policies.
        </li>
      </ul>
    </div>

    <div class="section" id="topics_of_interest">
      <h2>Topics of Interest</h2>
      <p>We will solicit papers relating to the following topics:
      <ul>
        <li> Cognitive Architecture
        <li> Human-Robot Interaction (HRI)
        <li> Social Learning and Theory of Mind
        <li> Learning and Planning for Tasks
        <li> Learning and Planning for Control
        <li> Reinforcement Learning
        <li> Sim2Real, Generative AI
        <li> Active Learning
        <li> Intuitive Physics
        <li> Multi-Agent Collaboration
        <li> Lifelong Learning
        <li> Meta-Reasoning and Meta-Cognition
        <li> Causality, Causal Reasoning, and Causal Learning
        <li> Efficient Adaptation of Large Models
        <li> Efficient Inference of Large Models
      </ul>
      </p>
    </div>

    <div class="section" id="committee" style="text-align: center">
      <h2>Organizing Committee</h2>
      <div class="grid">
        <div class="row justify-content-center">
          <div class="col-3" style="padding-bottom: 30px;">
            <a href="https://shivamvats.com/" target="_blank"><img src="imgs/shivam.png" class="rounded-circle"
                alt="Shivam Vats" width="140" height="140"></a>
            <h5 style="margin-bottom:0em;"> <a href="https://shivamvats.com/" target="_blank">Shivam Vats</a></h5>
            <h6>Brown University<br>USA</h6>
          </div>
          <br/> <br/>

          <div class="col-3" style="padding-bottom: 30px;">
            <a href="https://tabula-rosa.github.io/" target="_blank"><img src="imgs/tabitha.png" class="rounded-circle"
                alt="Tabitha Edith Lee" width="140" height="140"></a>
            <h5 style="margin-bottom:0em;"><a href="https://tabula-rosa.github.io/" target="_blank">Tabitha Edith Lee</a>
            </h5>
            <h6>Universit√© de Montr√©al &<br>Mila - Quebec AI Institute<br>Canada</h6>
          </div>
          <br /><br />

          <div class="col-3" style="padding-bottom: 30px;">
            <a href="https://chentoast.github.io/" target="_blank"><img src="imgs/tony.png" class="rounded-circle"
                alt="Tony Chen" width="140" height="140"></a>
            <h5 style="margin-bottom:0em;"><a href="https://chentoast.github.io/" target="_blank">Tony Chen</a>
            </h5>
            <h6>Massachusetts Institute<br>of Technology<br>USA</h6>
          </div>
          <br /><br />
        </div>

        <div class="row justify-content-center">
          <div class="col-3" style="padding-bottom: 30px;">
            <a href="https://jiayuanm.com/" target="_blank"><img src="imgs/jiayuan.png" class="rounded-circle"
                alt="Jiayun Mao" width="140" height="140"></a>
            <h5 style="margin-bottom:0em;"><a href="https://jiayuanm.com/" target="_blank">Jiayuan Mao</a>
            </h5>
            <h6>Massachusetts Institute<br>of Technology<br>USA</h6>
          </div>
          <br /><br />

          <div class="col-3" style="padding-bottom: 30px;">
            <a href="https://neo-x.github.io/" target="_blank"><img src="imgs/glen.png" class="rounded-circle"
                alt="Glen Berseth" width="140" height="140"></a>
            <h5 style="margin-bottom:0em;"><a href="https://neo-x.github.io/" target="_blank">Glen Berseth</a>
            </h5>
            <h6>Universit√© de Montr√©al &<br>Mila - Quebec AI Institute<br>Canada</h6>
          </div>
          <br /><br />

          <div class="col-3" style="padding-bottom: 30px;">
            <a href="https://cs.brown.edu/people/gdk/" target="_blank"><img src="imgs/george.png" class="rounded-circle"
                alt="George Konidaris" width="140" height="140"></a>
            <h5 style="margin-bottom:0em;"><a href="https://cs.brown.edu/people/gdk/" target="_blank">George Konidaris</a>
            </h5>
            <h6>Brown University<br>USA</h6>
          </div>
          <br /><br />
        </div>
      </div>
    </div>

    <div class="section" id="template" style="text-align: center">
      <h2>Template</h2>
      Our website was built by extending the websites of the <a href="https://leap-workshop.github.io/">Learning Effective Abstractions for Planning (CoRL 2024)</a> and the <a href="https://ai-workshops.github.io/generalizable-policy-learning-in-the-physical-world/">Generalizable Policy Learning in the Physical World (ICLR 2022)</a> workshops. We thank the organizers of these workshops for making their websites openly available.
    </div>

    <script src="javascripts/scale.fix.js"></script>
    <script>
      var coll = document.getElementsByClassName("collapsible");
      var i;

      for (i = 0; i < coll.length; i++) {
        coll[i].addEventListener("click", function () {
          this.classList.toggle("active");
          var content = this.nextElementSibling;
          if (content.style.display === "block") {
            content.style.display = "none";
          } else {
            content.style.display = "block";
          }
        });
      }
    </script>
</body>

</html>
